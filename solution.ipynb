{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69acd7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "from src.proj_utils import(\n",
    "    tokenize_text,\n",
    "    create_training_examples,\n",
    "    prepare_datasets,\n",
    "    build_vocabulary\n",
    ")\n",
    "\n",
    "from src.model import LSTMLangModel, train_model\n",
    "from src.dataset import TextGenerationDataset, create_dataloaders\n",
    "from src.evaluate_transformers import evaluate_distilgpt2_rouge, evaluate_text_generation, compare_models_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54f3594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/training.1600000.processed.noemoticon_reduced.csv', encoding='latin-1', header=None)\n",
    "df.columns = ['sentiment', 'id', 'date', 'flag', 'user', 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff929149",
   "metadata": {},
   "source": [
    "Блок приведения к нижнему регистру, удаления ссылок, упоминаний через @, спецсимоволов.\n",
    "После - удалить лишние символы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057cc252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.replace(r'http\\S+|www\\S+|@\\w+|[^\\w\\s]', '', regex=True)\n",
    "df['text'] = df['text'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17ac41",
   "metadata": {},
   "source": [
    "Получение токенов из текста публикаций и обучающих примеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba4719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized'] = df['text'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = create_training_examples(df['tokenized'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb546f71",
   "metadata": {},
   "source": [
    "Разделение на обучающую проверочную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5170f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = prepare_datasets(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Размеры данных:\")\n",
    "print(f\"Train: {len(X_train)} примеров\")\n",
    "print(f\"Validation: {len(X_val)} примеров\")\n",
    "print(f\"Test: {len(X_test)} примеров\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac7e3b7",
   "metadata": {},
   "source": [
    "Создать словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8e8b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = []\n",
    "for seq in X:\n",
    "    all_tokens.extend(seq)\n",
    "all_tokens.extend(Y)\n",
    "vocab = build_vocabulary([all_tokens], min_freq=1)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(f\"Размер словаря: {vocab_size}\")\n",
    "print(f\"Примеры слов в словаре: {list(vocab.keys())[:20]}\")\n",
    "\n",
    "\n",
    "test_words = [\"this\", \"is\", \"a\"]\n",
    "for word in test_words:\n",
    "    if word in vocab:\n",
    "        print(f\"'{word}' есть в словаре: индекс {vocab[word]}\")\n",
    "    else:\n",
    "        print(f\"'{word}' НЕТ в словаре!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2d302f",
   "metadata": {},
   "source": [
    "Создать загрузчиков данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0671ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "max_seq_length = 50\n",
    "\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "        vocab, batch_size, max_seq_length\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0e0fec",
   "metadata": {},
   "source": [
    "Создать модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21e7307",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Используемое устройство: {device}\")\n",
    "\n",
    "model = LSTMLangModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=256,\n",
    "    hidden_dim=512,\n",
    "    num_layers=2,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "print(f\"Количество параметров модели: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb3020d",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf8e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, val_rouge_scores = train_model(\n",
    "        model, train_loader, val_loader, vocab_size, device,\n",
    "        num_epochs=10, learning_rate=0.001\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21309032",
   "metadata": {},
   "source": [
    "Визуализация результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7582a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "#Потери\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "#Rouge метрики\n",
    "plt.subplot(1, 2, 2)\n",
    "rouge1_scores = [score.get('rouge1', 0) for score in val_rouge_scores if score]\n",
    "rouge2_scores = [score.get('rouge2', 0) for score in val_rouge_scores if score]\n",
    "rougeL_scores = [score.get('rougeL', 0) for score in val_rouge_scores if score]\n",
    "\n",
    "epochs = range(1, len(rouge1_scores) + 1)\n",
    "plt.plot(epochs, rouge1_scores, label='ROUGE-1', marker='o')\n",
    "plt.plot(epochs, rouge2_scores, label='ROUGE-2', marker='s')\n",
    "plt.plot(epochs, rougeL_scores, label='ROUGE-L', marker='^')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('ROUGE Score')\n",
    "plt.title('Validation ROUGE Scores')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_metrics.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nФинальные метрики:\")\n",
    "print(f\"Final Train Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Final Val Loss: {val_losses[-1]:.4f}\")\n",
    "if val_rouge_scores and val_rouge_scores[-1]:\n",
    "    print(f\"Final ROUGE-1: {val_rouge_scores[-1]['rouge1']:.4f}\")\n",
    "    print(f\"Final ROUGE-2: {val_rouge_scores[-1]['rouge2']:.4f}\")\n",
    "    print(f\"Final ROUGE-L: {val_rouge_scores[-1]['rougeL']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a027f11",
   "metadata": {},
   "source": [
    "Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        targets = batch['target'].to(device)\n",
    "        \n",
    "        outputs, _ = model(input_ids)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "print(f\"Значение потери на этапе тестирования: {avg_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a38719",
   "metadata": {},
   "source": [
    "Генерация связности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e8d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    ([\"i\", \"feel\", \"so\"], \"happy today because the sun is shining\"),\n",
    "    ([\"the\", \"movie\", \"was\"], \"really amazing with great special effects\"),\n",
    "    ([\"machine\", \"learning\", \"is\"], \"a fascinating field that continues to evolve\"),\n",
    "    ([\"the\", \"cat\", \"is\"], \"on the map\")\n",
    "]\n",
    "evaluate_text_generation(model, test_cases, vocab, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641a6e57",
   "metadata": {},
   "source": [
    "Оценка с использованием distilgpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5844aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_texts = []\n",
    "for i, (x_seq, y_token) in enumerate(zip(X_val, y_val)):\n",
    "    if i < 100:  # Ограничение количества для скорости\n",
    "        text = ' '.join(x_seq) + ' ' + y_token\n",
    "        val_texts.append(text)\n",
    "\n",
    "gpt2_results = evaluate_distilgpt2_rouge(val_texts[:50])\n",
    "print(\"\\nСравнение моделей:\")\n",
    "print(f\"LSTM ROUGE-1: {val_rouge_scores[-1]['rouge1']:.4f}\")\n",
    "print(f\"DistilGPT2 ROUGE-1: {gpt2_results['rouge1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5f0caa",
   "metadata": {},
   "source": [
    "Прямое сравнение генераций LSTM и DistilGPT2 на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca97fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_generator = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=\"distilgpt2\",\n",
    "    device=device if torch.cuda.is_available() else -1,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    ")\n",
    "gpt2_tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n",
    "\n",
    "# Тестовые примеры из тестовой выборки (возьмите реальные примеры)\n",
    "test_examples_from_dataset = [\n",
    "    (X_test[i][-3:], y_test[i]) for i in range(min(10, len(X_test)))\n",
    "]\n",
    "\n",
    "print(\"Сравнение на реальных примерах из тестовой выборки:\")\n",
    "compare_models_generation(\n",
    "    model, \n",
    "    test_examples_from_dataset, \n",
    "    vocab, \n",
    "    device, \n",
    "    gpt2_generator, \n",
    "    gpt2_tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229dc8e8",
   "metadata": {},
   "source": [
    "Сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1063ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"models/lstm_language_model.pth\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'vocab': vocab,\n",
    "        'model_config': {\n",
    "            'vocab_size': vocab_size,\n",
    "            'embedding_dim': 256,\n",
    "            'hidden_dim': 512,\n",
    "            'num_layers': 2,\n",
    "            'dropout': 0.3\n",
    "        }\n",
    "    }, save_path)\n",
    "print(f\"Модель сохранена в: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3afca8",
   "metadata": {},
   "source": [
    "# Вывод\n",
    "\n",
    "Обучение проходило на выборке в 100 000 записей. Результат на основе LSTM превосходит DistilGPT2:\n",
    "\n",
    "LSTM ROUGE-1: <b>0.1184</b><br>\n",
    "DistilGPT2 ROUGE-1: <b>0.0271</b>\n",
    "\n",
    "Разные сесси обучения на одних и тех же исходных данных не показывают стабильного результата для LSTM по методике ROUGE (0.11 - 0.45))<br/>\n",
    "Результаты сравнения генерации LSTM и distil-gpt2 представлены выше\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
